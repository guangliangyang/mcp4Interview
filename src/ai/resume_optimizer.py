"""
ç®€å†ä¼˜åŒ–å™¨
åŸºäºèŒä½è¦æ±‚ä¼˜åŒ–ç®€å†å†…å®¹å’Œå…³é”®è¯
"""

import asyncio
import logging
import re
from typing import Dict, List, Tuple, Optional
from collections import Counter

from src.utils.logger import get_logger

logger = get_logger(__name__)

class ResumeOptimizer:
    """ç®€å†ä¼˜åŒ–å™¨"""

    def __init__(self, ai_config: Dict):
        self.config = ai_config
        self.client = self._initialize_ai_client()

        # ATSå…³é”®è¯æƒé‡
        self.ats_weights = {
            'exact_match': 1.0,      # å®Œå…¨åŒ¹é…
            'synonym_match': 0.8,    # åŒä¹‰è¯åŒ¹é…
            'partial_match': 0.6,    # éƒ¨åˆ†åŒ¹é…
            'related_match': 0.4     # ç›¸å…³åŒ¹é…
        }

    def _initialize_ai_client(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        try:
            if self.config.get('anthropic_api_key'):
                import anthropic
                return anthropic.Anthropic(api_key=self.config['anthropic_api_key'])
            elif self.config.get('openai_api_key'):
                import openai
                return openai.OpenAI(api_key=self.config['openai_api_key'])
            else:
                logger.info("æœªé…ç½®AI APIå¯†é’¥ï¼Œä½¿ç”¨åŸºç¡€ä¼˜åŒ–ç®—æ³•")
                return None
        except ImportError as e:
            logger.error(f"AIåº“å¯¼å…¥å¤±è´¥: {e}")
            return None

    async def optimize_keywords(self, resume_content: str, job_posting: str) -> str:
        """ä¼˜åŒ–ç®€å†å…³é”®è¯

        Args:
            resume_content: åŸå§‹ç®€å†å†…å®¹
            job_posting: èŒä½æè¿°

        Returns:
            ä¼˜åŒ–åçš„ç®€å†å†…å®¹
        """
        try:
            if self.client:
                return await self._ai_keyword_optimization(resume_content, job_posting)
            else:
                return await self._basic_keyword_optimization(resume_content, job_posting)

        except Exception as e:
            logger.error(f"å…³é”®è¯ä¼˜åŒ–å¤±è´¥: {e}")
            return resume_content

    async def _ai_keyword_optimization(self, resume_content: str, job_posting: str) -> str:
        """ä½¿ç”¨AIè¿›è¡Œå…³é”®è¯ä¼˜åŒ–"""
        try:
            prompt = self._build_optimization_prompt(resume_content, job_posting)

            if 'anthropic' in str(type(self.client)):
                # Claude API
                message = self.client.messages.create(
                    model=self.config.get('default_model', 'claude-3-sonnet-20240229'),
                    max_tokens=self.config.get('max_tokens', 3000),
                    temperature=self.config.get('temperature', 0.5),
                    messages=[{"role": "user", "content": prompt}]
                )
                return message.content[0].text

            elif 'openai' in str(type(self.client)):
                # OpenAI API
                response = self.client.chat.completions.create(
                    model=self.config.get('default_model', 'gpt-3.5-turbo'),
                    max_tokens=self.config.get('max_tokens', 3000),
                    temperature=self.config.get('temperature', 0.5),
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content

        except Exception as e:
            logger.error(f"AIå…³é”®è¯ä¼˜åŒ–å¤±è´¥: {e}")
            return await self._basic_keyword_optimization(resume_content, job_posting)

    def _build_optimization_prompt(self, resume_content: str, job_posting: str) -> str:
        """æ„å»ºä¼˜åŒ–æç¤º"""
        prompt = f"""
ä½œä¸ºä¸€åä¸“ä¸šçš„ç®€å†ä¼˜åŒ–ä¸“å®¶å’ŒATSç³»ç»Ÿä¸“å®¶ï¼Œè¯·ä¼˜åŒ–ä»¥ä¸‹ç®€å†ä»¥åŒ¹é…ç›®æ ‡èŒä½ã€‚

**ç›®æ ‡èŒä½æè¿°ï¼š**
{job_posting[:2000]}

**åŸå§‹ç®€å†å†…å®¹ï¼š**
{resume_content[:2000]}

**ä¼˜åŒ–è¦æ±‚ï¼š**

1. **å…³é”®è¯ä¼˜åŒ–**
   - è¯†åˆ«èŒä½æè¿°ä¸­çš„å…³é”®æŠ€èƒ½å’Œè¦æ±‚
   - åœ¨ç®€å†ä¸­è‡ªç„¶åœ°èå…¥è¿™äº›å…³é”®è¯
   - ç¡®ä¿å…³é”®è¯çš„ä½¿ç”¨ç¬¦åˆä¸Šä¸‹æ–‡
   - ä¼˜åŒ–æŠ€èƒ½å…³é”®è¯ä»¥æé«˜ATSé€šè¿‡ç‡

2. **æŠ€èƒ½éƒ¨åˆ†å¼ºåŒ–**
   - é‡æ–°æ’åˆ—æŠ€èƒ½éƒ¨åˆ†ï¼Œä¼˜å…ˆå±•ç¤ºåŒ¹é…çš„æŠ€èƒ½
   - æ·»åŠ èŒä½è¦æ±‚ä¸­æåˆ°ä½†ç®€å†ä¸­ç¼ºå¤±çš„ç›¸å…³æŠ€èƒ½
   - ä½¿ç”¨ä¸èŒä½æè¿°ä¸€è‡´çš„æŠ€æœ¯æœ¯è¯­

3. **ç»éªŒæè¿°ä¼˜åŒ–**
   - è°ƒæ•´å·¥ä½œç»éªŒæè¿°ï¼Œçªå‡ºä¸ç›®æ ‡èŒä½ç›¸å…³çš„æˆæœ
   - ä½¿ç”¨é‡åŒ–æ•°æ®å¢å¼ºè¯´æœåŠ›
   - é‡‡ç”¨è¡ŒåŠ¨å¯¼å‘çš„è¯­è¨€ï¼ˆAction-Result formatï¼‰

4. **æ ¼å¼å’Œç»“æ„ä¼˜åŒ–**
   - ç¡®ä¿é‡è¦å…³é”®è¯åœ¨ç®€å†å‰1/3éƒ¨åˆ†å‡ºç°
   - ä¼˜åŒ–æ®µè½ç»“æ„ï¼Œæé«˜å¯è¯»æ€§
   - ä¿æŒä¸“ä¸šæ ¼å¼

5. **ATSå‹å¥½æ€§**
   - ä½¿ç”¨æ ‡å‡†çš„ç®€å†æ®µè½æ ‡é¢˜
   - é¿å…ä½¿ç”¨å›¾è¡¨ã€ç‰¹æ®Šå­—ç¬¦
   - ç¡®ä¿å…³é”®ä¿¡æ¯æ˜“äºæœºå™¨è§£æ

**è¯·è¿”å›ä¼˜åŒ–åçš„å®Œæ•´ç®€å†å†…å®¹ï¼Œä¿æŒåŸæœ‰çš„åŸºæœ¬ä¿¡æ¯å’Œç»å†ï¼Œä½†è¦æ˜¾è‘—æé«˜ä¸ç›®æ ‡èŒä½çš„åŒ¹é…åº¦ã€‚**

ä¼˜åŒ–åçš„ç®€å†ï¼š
"""
        return prompt

    async def _basic_keyword_optimization(self, resume_content: str, job_posting: str) -> str:
        """åŸºç¡€å…³é”®è¯ä¼˜åŒ–ï¼ˆæ— AIï¼‰"""
        try:
            # æå–èŒä½å…³é”®è¯
            job_keywords = self._extract_job_keywords(job_posting)

            # åˆ†æå½“å‰ç®€å†å…³é”®è¯
            resume_keywords = self._extract_resume_keywords(resume_content)

            # æ‰¾å‡ºç¼ºå¤±çš„å…³é”®è¯
            missing_keywords = self._find_missing_keywords(job_keywords, resume_keywords)

            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            optimized_content = self._apply_basic_optimizations(
                resume_content, job_keywords, missing_keywords
            )

            return optimized_content

        except Exception as e:
            logger.error(f"åŸºç¡€å…³é”®è¯ä¼˜åŒ–å¤±è´¥: {e}")
            return resume_content

    def _extract_job_keywords(self, job_posting: str) -> Dict[str, List[str]]:
        """æå–èŒä½å…³é”®è¯"""
        keywords = {
            'technical_skills': [],
            'soft_skills': [],
            'tools': [],
            'certifications': [],
            'experience_keywords': []
        }

        # æŠ€æœ¯æŠ€èƒ½å…³é”®è¯
        technical_patterns = [
            r'\b(Python|JavaScript|Java|C\+\+|C#|Go|Rust|PHP|Ruby|Scala|Kotlin|Swift|TypeScript)\b',
            r'\b(React|Vue|Angular|Django|Flask|Spring|Express|Laravel|Rails|ASP\.NET)\b',
            r'\b(AWS|Azure|GCP|Docker|Kubernetes|Jenkins|Git|Terraform|Ansible)\b',
            r'\b(MySQL|PostgreSQL|MongoDB|Redis|Elasticsearch|Oracle|SQL Server)\b'
        ]

        # è½¯æŠ€èƒ½å…³é”®è¯
        soft_skills_patterns = [
            r'\b(leadership|communication|teamwork|problem[- ]solving|analytical|creative|strategic)\b',
            r'\b(project management|agile|scrum|collaboration|mentoring|coaching)\b'
        ]

        # ç»éªŒç›¸å…³å…³é”®è¯
        experience_patterns = [
            r'\b(\d+\+?\s*years?|experience|background|expertise|proficiency)\b',
            r'\b(senior|lead|principal|architect|manager|director)\b',
            r'\b(develop|build|design|implement|manage|lead|coordinate)\b'
        ]

        job_lower = job_posting.lower()

        # æå–æŠ€æœ¯æŠ€èƒ½
        for pattern in technical_patterns:
            matches = re.findall(pattern, job_lower, re.IGNORECASE)
            keywords['technical_skills'].extend(matches)

        # æå–è½¯æŠ€èƒ½
        for pattern in soft_skills_patterns:
            matches = re.findall(pattern, job_lower, re.IGNORECASE)
            keywords['soft_skills'].extend(matches)

        # æå–ç»éªŒå…³é”®è¯
        for pattern in experience_patterns:
            matches = re.findall(pattern, job_lower, re.IGNORECASE)
            keywords['experience_keywords'].extend(matches)

        # å»é‡å¹¶æ’åº
        for category in keywords:
            keywords[category] = list(set(keywords[category]))
            keywords[category].sort(key=len, reverse=True)  # é•¿è¯ä¼˜å…ˆ

        return keywords

    def _extract_resume_keywords(self, resume_content: str) -> Dict[str, List[str]]:
        """æå–ç®€å†å…³é”®è¯"""
        return self._extract_job_keywords(resume_content)  # å¤ç”¨é€»è¾‘

    def _find_missing_keywords(self, job_keywords: Dict, resume_keywords: Dict) -> Dict[str, List[str]]:
        """æ‰¾å‡ºç¼ºå¤±çš„å…³é”®è¯"""
        missing = {}

        for category in job_keywords:
            job_set = set(keyword.lower() for keyword in job_keywords[category])
            resume_set = set(keyword.lower() for keyword in resume_keywords.get(category, []))

            missing_set = job_set - resume_set
            missing[category] = list(missing_set)

        return missing

    def _apply_basic_optimizations(
        self,
        resume_content: str,
        job_keywords: Dict,
        missing_keywords: Dict
    ) -> str:
        """åº”ç”¨åŸºç¡€ä¼˜åŒ–"""
        optimized_content = resume_content

        # åˆ›å»ºä¼˜åŒ–å»ºè®®è€Œä¸æ˜¯ç›´æ¥ä¿®æ”¹ç®€å†
        optimization_suggestions = self._generate_optimization_suggestions(
            job_keywords, missing_keywords
        )

        # åœ¨ç®€å†æœ«å°¾æ·»åŠ ä¼˜åŒ–å»ºè®®
        optimized_content += "\n\n" + "="*50
        optimized_content += "\nğŸ“Š ç®€å†ä¼˜åŒ–å»ºè®®\n"
        optimized_content += "="*50 + "\n"
        optimized_content += optimization_suggestions

        return optimized_content

    def _generate_optimization_suggestions(self, job_keywords: Dict, missing_keywords: Dict) -> str:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []

        # åˆ†æç¼ºå¤±çš„æŠ€æœ¯æŠ€èƒ½
        if missing_keywords.get('technical_skills'):
            suggestions.append("ğŸ”§ **æŠ€æœ¯æŠ€èƒ½ä¼˜åŒ–**")
            suggestions.append("å»ºè®®åœ¨ç®€å†ä¸­æ·»åŠ ä»¥ä¸‹æŠ€èƒ½ï¼ˆå¦‚æœä½ æœ‰ç›¸å…³ç»éªŒï¼‰ï¼š")
            for skill in missing_keywords['technical_skills'][:5]:
                suggestions.append(f"   â€¢ {skill.title()}")
            suggestions.append("")

        # åˆ†æç¼ºå¤±çš„è½¯æŠ€èƒ½
        if missing_keywords.get('soft_skills'):
            suggestions.append("ğŸ’¡ **è½¯æŠ€èƒ½å¼ºåŒ–**")
            suggestions.append("å»ºè®®åœ¨å·¥ä½œç»éªŒä¸­ä½“ç°ä»¥ä¸‹èƒ½åŠ›ï¼š")
            for skill in missing_keywords['soft_skills'][:3]:
                suggestions.append(f"   â€¢ {skill.title()}")
            suggestions.append("")

        # å…³é”®è¯å¯†åº¦åˆ†æ
        all_job_keywords = []
        for category in job_keywords.values():
            all_job_keywords.extend(category)

        if all_job_keywords:
            suggestions.append("ğŸ“ˆ **å…³é”®è¯ä¼˜åŒ–**")
            suggestions.append("èŒä½æè¿°ä¸­çš„é«˜é¢‘å…³é”®è¯ï¼š")
            keyword_counter = Counter(all_job_keywords)
            for keyword, count in keyword_counter.most_common(8):
                suggestions.append(f"   â€¢ {keyword.title()} (å‡ºç° {count} æ¬¡)")
            suggestions.append("")

        # ATSä¼˜åŒ–å»ºè®®
        suggestions.append("ğŸ¤– **ATSç³»ç»Ÿä¼˜åŒ–**")
        suggestions.append("   â€¢ ä½¿ç”¨æ ‡å‡†çš„ç®€å†æ®µè½æ ‡é¢˜ï¼ˆå¦‚ 'Professional Experience'ï¼‰")
        suggestions.append("   â€¢ åœ¨ç®€å†å‰1/3éƒ¨åˆ†åŒ…å«å…³é”®æŠ€èƒ½")
        suggestions.append("   â€¢ ä½¿ç”¨é¡¹ç›®ç¬¦å·åˆ—ä¸¾æŠ€èƒ½å’Œæˆå°±")
        suggestions.append("   â€¢ é¿å…ä½¿ç”¨è¡¨æ ¼ã€å›¾ç‰‡æˆ–ç‰¹æ®Šæ ¼å¼")
        suggestions.append("   â€¢ ç¡®ä¿è”ç³»ä¿¡æ¯æ¸…æ™°å¯è¯»")
        suggestions.append("")

        # é‡åŒ–å»ºè®®
        suggestions.append("ğŸ“Š **æˆæœé‡åŒ–å»ºè®®**")
        suggestions.append("   â€¢ ä½¿ç”¨å…·ä½“æ•°å­—æè¿°é¡¹ç›®è§„æ¨¡å’Œå½±å“")
        suggestions.append("   â€¢ çªå‡ºæ”¹è¿›æ•ˆæœï¼ˆå¦‚'æå‡æ•ˆç‡30%'ï¼‰")
        suggestions.append("   â€¢ å¼ºè°ƒå›¢é˜Ÿè§„æ¨¡å’Œç®¡ç†ç»éªŒ")
        suggestions.append("   â€¢ å±•ç¤ºæŠ€æœ¯é¡¹ç›®çš„ç”¨æˆ·é‡æˆ–æ€§èƒ½æå‡")
        suggestions.append("")

        return "\n".join(suggestions)

    async def analyze_ats_compatibility(self, resume_content: str) -> Dict[str, any]:
        """åˆ†æATSå…¼å®¹æ€§"""
        try:
            analysis = {
                'score': 0,
                'issues': [],
                'recommendations': [],
                'keyword_density': {},
                'format_score': 0
            }

            # æ ¼å¼åˆ†æ
            format_issues = self._analyze_format_compatibility(resume_content)
            analysis['issues'].extend(format_issues)

            # å…³é”®è¯å¯†åº¦åˆ†æ
            keyword_analysis = self._analyze_keyword_density(resume_content)
            analysis['keyword_density'] = keyword_analysis

            # ç»“æ„åˆ†æ
            structure_score = self._analyze_resume_structure(resume_content)
            analysis['format_score'] = structure_score

            # è®¡ç®—æ€»ä½“è¯„åˆ†
            analysis['score'] = self._calculate_ats_score(analysis)

            # ç”Ÿæˆå»ºè®®
            analysis['recommendations'] = self._generate_ats_recommendations(analysis)

            return analysis

        except Exception as e:
            logger.error(f"ATSå…¼å®¹æ€§åˆ†æå¤±è´¥: {e}")
            return {'score': 0, 'error': str(e)}

    def _analyze_format_compatibility(self, resume_content: str) -> List[str]:
        """åˆ†ææ ¼å¼å…¼å®¹æ€§"""
        issues = []

        # æ£€æŸ¥ç‰¹æ®Šå­—ç¬¦
        special_chars = re.findall(r'[^\w\s\-.,()@/:]', resume_content)
        if len(special_chars) > 10:
            issues.append("åŒ…å«è¿‡å¤šç‰¹æ®Šå­—ç¬¦ï¼Œå¯èƒ½å½±å“ATSè§£æ")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡å‡†æ®µè½æ ‡é¢˜
        standard_sections = [
            'experience', 'education', 'skills', 'summary', 'objective'
        ]
        found_sections = 0
        for section in standard_sections:
            if section.lower() in resume_content.lower():
                found_sections += 1

        if found_sections < 3:
            issues.append("ç¼ºå°‘æ ‡å‡†ç®€å†æ®µè½æ ‡é¢˜")

        # æ£€æŸ¥è”ç³»ä¿¡æ¯
        if not re.search(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', resume_content):
            issues.append("æœªæ‰¾åˆ°æœ‰æ•ˆçš„é‚®ç®±åœ°å€")

        return issues

    def _analyze_keyword_density(self, resume_content: str) -> Dict[str, int]:
        """åˆ†æå…³é”®è¯å¯†åº¦"""
        # æå–å…³é”®è¯å¹¶ç»Ÿè®¡é¢‘ç‡
        words = re.findall(r'\b\w{4,}\b', resume_content.lower())
        word_counter = Counter(words)

        # è¿‡æ»¤åœç”¨è¯
        stop_words = {
            'experience', 'work', 'company', 'project', 'team', 'development',
            'management', 'application', 'system', 'technology', 'business'
        }

        filtered_counter = {
            word: count for word, count in word_counter.items()
            if word not in stop_words and count > 1
        }

        return dict(filtered_counter.most_common(15))

    def _analyze_resume_structure(self, resume_content: str) -> float:
        """åˆ†æç®€å†ç»“æ„è¯„åˆ†"""
        score = 0.0

        # é•¿åº¦æ£€æŸ¥ (1-2é¡µæœ€ä½³)
        word_count = len(resume_content.split())
        if 300 <= word_count <= 800:
            score += 25

        # æ®µè½ç»“æ„æ£€æŸ¥
        paragraphs = resume_content.split('\n\n')
        if 4 <= len(paragraphs) <= 8:
            score += 25

        # é¡¹ç›®ç¬¦å·ä½¿ç”¨
        bullet_points = resume_content.count('â€¢') + resume_content.count('-')
        if bullet_points >= 5:
            score += 25

        # æ•°å­—å’Œé‡åŒ–æŒ‡æ ‡
        numbers = re.findall(r'\d+', resume_content)
        if len(numbers) >= 8:
            score += 25

        return score

    def _calculate_ats_score(self, analysis: Dict) -> float:
        """è®¡ç®—ATSæ€»è¯„åˆ†"""
        base_score = 100.0

        # æ‰£åˆ†é¡¹
        penalty = len(analysis['issues']) * 10
        base_score -= penalty

        # æ ¼å¼è¯„åˆ†æƒé‡
        format_weight = 0.4
        keyword_weight = 0.6

        format_score = analysis['format_score']
        keyword_score = min(len(analysis['keyword_density']) * 5, 60)  # å…³é”®è¯å¤šæ ·æ€§

        total_score = (format_score * format_weight + keyword_score * keyword_weight)
        return max(0, min(100, total_score))

    def _generate_ats_recommendations(self, analysis: Dict) -> List[str]:
        """ç”ŸæˆATSä¼˜åŒ–å»ºè®®"""
        recommendations = []

        if analysis['score'] < 60:
            recommendations.append("ğŸ”´ ATSå…¼å®¹æ€§éœ€è¦é‡å¤§æ”¹è¿›")
        elif analysis['score'] < 80:
            recommendations.append("ğŸŸ¡ ATSå…¼å®¹æ€§è‰¯å¥½ï¼Œä½†æœ‰æ”¹è¿›ç©ºé—´")
        else:
            recommendations.append("ğŸŸ¢ ATSå…¼å®¹æ€§ä¼˜ç§€")

        # å…·ä½“å»ºè®®
        if analysis['issues']:
            recommendations.append("**ç«‹å³è§£å†³çš„é—®é¢˜ï¼š**")
            recommendations.extend([f"  â€¢ {issue}" for issue in analysis['issues']])

        if analysis['keyword_density']:
            recommendations.append("**å…³é”®è¯ä¼˜åŒ–ï¼š**")
            recommendations.append("  â€¢ é€‚å½“å¢åŠ ä»¥ä¸‹é«˜é¢‘è¯æ±‡çš„ä½¿ç”¨ï¼š")
            top_keywords = list(analysis['keyword_density'].keys())[:5]
            recommendations.append(f"    {', '.join(top_keywords)}")

        return recommendations

if __name__ == "__main__":
    async def test_resume_optimizer():
        """æµ‹è¯•ç®€å†ä¼˜åŒ–å™¨"""
        config = {
            'anthropic_api_key': '',  # éœ€è¦å®é™…çš„APIå¯†é’¥
            'default_model': 'claude-3-sonnet-20240229',
            'max_tokens': 3000,
            'temperature': 0.5
        }

        optimizer = ResumeOptimizer(config)

        sample_resume = """
        John Smith
        Software Developer
        john.smith@email.com | (555) 123-4567

        EXPERIENCE
        Senior Developer at TechCorp (2020-2024)
        - Developed web applications using Python and JavaScript
        - Worked with databases and APIs
        - Led a small team of developers

        EDUCATION
        Bachelor of Computer Science, University of Technology (2016-2020)

        SKILLS
        Programming: Python, JavaScript, HTML, CSS
        Databases: MySQL, PostgreSQL
        """

        job_posting = """
        Senior Python Developer - Remote

        We are seeking a Senior Python Developer with expertise in:
        - 5+ years Python development experience
        - Django and Flask frameworks
        - REST API development and integration
        - AWS cloud services (EC2, S3, RDS)
        - Docker containerization
        - PostgreSQL and Redis databases
        - Agile development methodologies
        - Strong problem-solving and communication skills

        Responsibilities:
        - Design and develop scalable web applications
        - Lead technical architecture decisions
        - Mentor junior developers
        - Collaborate with cross-functional teams
        """

        optimized = await optimizer.optimize_keywords(sample_resume, job_posting)
        print("ä¼˜åŒ–åçš„ç®€å†ï¼š")
        print(optimized)
        print("\n" + "="*60 + "\n")

        # ATSå…¼å®¹æ€§åˆ†æ
        ats_analysis = await optimizer.analyze_ats_compatibility(sample_resume)
        print("ATSå…¼å®¹æ€§åˆ†æï¼š")
        print(f"è¯„åˆ†: {ats_analysis['score']:.1f}/100")
        print("å»ºè®®ï¼š")
        for rec in ats_analysis['recommendations']:
            print(f"  {rec}")

    asyncio.run(test_resume_optimizer())